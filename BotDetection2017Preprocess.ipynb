{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/u2200579/Bot-Detection/blob/main/BotDetection2017Preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQSYwjM8jqMk",
        "outputId": "05e6312d-e178-49e6-f314-1bdf08d6399f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKZpzoaaFnPo",
        "outputId": "6b4feb3b-1f55-4772-8ebd-e7f5974a1511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 13.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2022.6.15)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ],
      "source": [
        "pip install vaderSentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfZACMGlFsvN",
        "outputId": "a1585e22-dbe1-41f8-ee38-9eb0eab7a741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.0.0.tar.gz (197 kB)\n",
            "\u001b[K     |████████████████████████████████| 197 kB 15.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.0.0-py3-none-any.whl size=193022 sha256=82cc8bc1f633f777c87ea462905af7f51dc3ff9953a952bd0de57b79c2303b4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/29/4d/3cfe7452ac7d8d83b1930f8a6205c3c9649b24e80f9029fc38\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-2.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XZLh-aGr3l0",
        "outputId": "69443624-67af-4ab6-d80e-8817e796019d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import emoji\n",
        "from textblob import TextBlob\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import gensim\n",
        "import gensim.downloader\n",
        "import nltk  \n",
        "nltk.download('punkt')\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WGz8YR3rnLVs"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/My Drive/genuineusers.csv\" \"genuineusers.csv\" #Import user Profile information for geneuine users and bots\n",
        "!cp \"/content/drive/My Drive/SS1users.csv\" \"SS1users.csv\"\n",
        "!cp \"/content/drive/My Drive/SS2users.csv\" \"SS2users.csv\"\n",
        "!cp \"/content/drive/My Drive/SS3users.csv\" \"SS3users.csv\"\n",
        "!cp \"/content/drive/My Drive/TS1users.csv\" \"TS1users.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/My Drive/Dataset1Tweets.csv\" \"tweets.csv\" #Import Tweet information for geneuine users and bots"
      ],
      "metadata": {
        "id": "-oOJr9Q1P6U1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "maJyDdZVqFM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcad6942-9e26-4e78-f2a0-43bf7a4c2779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fake users done!\n",
            "Human users done!\n"
          ]
        }
      ],
      "source": [
        "dfs = []\n",
        "\n",
        "dfs.append(pd.read_csv(\"SS1users.csv\",parse_dates=['created_at']))\n",
        "dfs.append(pd.read_csv(\"SS2users.csv\",parse_dates=['created_at']))\n",
        "dfs.append(pd.read_csv(\"SS3users.csv\",parse_dates=['created_at']))\n",
        "dfs1 = pd.read_csv(\"TS1users.csv\",parse_dates=['created_at'])\n",
        "dfs1['created_at'] = dfs1['created_at'].str.replace(r'\\D+', '', regex=True).astype('int')\n",
        "dfs1['created_at'] = pd.to_datetime(dfs1['created_at'],unit='ms')\n",
        "dfs1['is_bot'] = 1\n",
        "dfs1['Data'] = 'TraditionalSocialSpambot'\n",
        "\n",
        "botsCsv = pd.concat(dfs, axis=0, sort=True)\n",
        "botsCsv['is_bot'] = 1\n",
        "botsCsv['Data'] = 'SocialSpambot'\n",
        "print(\"Fake users done!\")\n",
        "dfs2 = []\n",
        "dfs2.append(pd.read_csv(\"genuineusers.csv\",parse_dates=['created_at']))\n",
        "\n",
        "print(\"Human users done!\")\n",
        "\n",
        "humansCsv = pd.concat(dfs2, sort=True)\n",
        "humansCsv['is_bot']=0\n",
        "humansCsv['Data']='Human'\n",
        "\n",
        "resultUsers = pd.concat([botsCsv, dfs1, humansCsv], sort=True)\n",
        "resultUsers['created_at'] = pd.to_datetime(resultUsers['created_at'],utc=True)\n",
        "resultUsers['crawled_at'] = pd.to_datetime(resultUsers['crawled_at'],utc=True)\n",
        "users = pd.DataFrame()\n",
        "users['id']=resultUsers['id']\n",
        "users['status_count'] = resultUsers['statuses_count']\n",
        "users['friends_count'] = resultUsers['friends_count']\n",
        "users['favorites_count'] = resultUsers['favourites_count']\n",
        "users['followers_count'] = resultUsers['followers_count']\n",
        "users['friends_to_followers_ratio'] = resultUsers['friends_count']/resultUsers['followers_count']\n",
        "users['listed_count'] = resultUsers['listed_count']\n",
        "users['is_bot'] = resultUsers['is_bot']\n",
        "users['Account_age'] = (resultUsers['crawled_at'] - resultUsers['created_at']).dt.days\n",
        "users['Data'] = resultUsers['Data']\n",
        "users['description'] = resultUsers['description']\n",
        "users['screen_name'] = resultUsers['screen_name']\n",
        "users['name'] = resultUsers['name']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"tweets.csv\") #datasets of bots and genuine accounts"
      ],
      "metadata": {
        "id": "wN4fxrcKP4zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae33adad-16ab-4fa5-a37b-8cbe8b049483"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (7,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.head()\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "YP_S1Ytj-MqR",
        "outputId": "67dc8464-4727-4010-fcc8-97bb25a3f74d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   contributors           crawled_at                      created_at  \\\n",
              "0           NaN  2014-11-12 21:44:09  Wed Nov 12 20:14:48 +0000 2014   \n",
              "1           NaN  2014-11-12 21:44:09  Wed Nov 12 20:01:32 +0000 2014   \n",
              "2           NaN  2014-11-12 21:44:09  Wed Nov 12 12:41:32 +0000 2014   \n",
              "3           NaN  2014-11-12 21:44:09  Tue Nov 11 22:23:43 +0000 2014   \n",
              "4           NaN  2014-11-12 21:44:09  Tue Nov 11 22:17:01 +0000 2014   \n",
              "\n",
              "   favorite_count  favorited  geo                  id in_reply_to_screen_name  \\\n",
              "0             0.0        NaN  NaN  532627591686275072                     NaN   \n",
              "1             0.0        NaN  NaN  532624255058706432                     NaN   \n",
              "2             0.0        NaN  NaN  532513524460052480                     NaN   \n",
              "3             0.0        NaN  NaN  532297646669852672                     NaN   \n",
              "4             0.0        NaN  NaN  532295960807100416                     NaN   \n",
              "\n",
              "   in_reply_to_status_id  in_reply_to_user_id  ...  reply_count  \\\n",
              "0                    0.0                  0.0  ...          0.0   \n",
              "1                    0.0                  0.0  ...          0.0   \n",
              "2                    0.0                  0.0  ...          0.0   \n",
              "3                    0.0                  0.0  ...          0.0   \n",
              "4                    0.0                  0.0  ...          0.0   \n",
              "\n",
              "   retweet_count  retweeted  retweeted_status_id  \\\n",
              "0            0.0        NaN                  0.0   \n",
              "1            0.0        NaN                  0.0   \n",
              "2            0.0        NaN                  0.0   \n",
              "3            0.0        NaN                  0.0   \n",
              "4            0.0        NaN                  0.0   \n",
              "\n",
              "                                              source  \\\n",
              "0  <a href=\"http://www.facebook.com/twitter\" rel=...   \n",
              "1  <a href=\"http://www.facebook.com/twitter\" rel=...   \n",
              "2  <a href=\"http://www.facebook.com/twitter\" rel=...   \n",
              "3  <a href=\"http://www.facebook.com/twitter\" rel=...   \n",
              "4  <a href=\"http://www.facebook.com/twitter\" rel=...   \n",
              "\n",
              "                                                text            timestamp  \\\n",
              "0   I Pooh - In silenzio 1968 http://t.co/ahvQxUqTws  2014-11-12 21:14:48   \n",
              "1                             http://t.co/HyI5EQKz6Q  2014-11-12 21:01:32   \n",
              "2  Tutti a tavola, con il filetto di baccalÃ . ht...  2014-11-12 13:41:32   \n",
              "3                             http://t.co/NAHQ4l2pUy  2014-11-11 23:23:43   \n",
              "4       Gold - Spandau Ballet http://t.co/o8ZJHt7Neu  2014-11-11 23:17:01   \n",
              "\n",
              "   truncated              updated     user_id  \n",
              "0        NaN  2014-11-12 21:44:09  24858289.0  \n",
              "1        NaN  2014-11-12 21:44:09  24858289.0  \n",
              "2        NaN  2014-11-12 21:44:09  24858289.0  \n",
              "3        NaN  2014-11-12 21:44:09  24858289.0  \n",
              "4        NaN  2014-11-12 21:44:09  24858289.0  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70b1e6fe-16de-454c-9511-17abcc2bd436\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contributors</th>\n",
              "      <th>crawled_at</th>\n",
              "      <th>created_at</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>favorited</th>\n",
              "      <th>geo</th>\n",
              "      <th>id</th>\n",
              "      <th>in_reply_to_screen_name</th>\n",
              "      <th>in_reply_to_status_id</th>\n",
              "      <th>in_reply_to_user_id</th>\n",
              "      <th>...</th>\n",
              "      <th>reply_count</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>retweeted</th>\n",
              "      <th>retweeted_status_id</th>\n",
              "      <th>source</th>\n",
              "      <th>text</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>truncated</th>\n",
              "      <th>updated</th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2014-11-12 21:44:09</td>\n",
              "      <td>Wed Nov 12 20:14:48 +0000 2014</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>532627591686275072</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>&lt;a href=\"http://www.facebook.com/twitter\" rel=...</td>\n",
              "      <td>I Pooh - In silenzio 1968 http://t.co/ahvQxUqTws</td>\n",
              "      <td>2014-11-12 21:14:48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2014-11-12 21:44:09</td>\n",
              "      <td>24858289.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2014-11-12 21:44:09</td>\n",
              "      <td>Wed Nov 12 20:01:32 +0000 2014</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>532624255058706432</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>&lt;a href=\"http://www.facebook.com/twitter\" rel=...</td>\n",
              "      <td>http://t.co/HyI5EQKz6Q</td>\n",
              "      <td>2014-11-12 21:01:32</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2014-11-12 21:44:09</td>\n",
              "      <td>24858289.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2014-11-12 21:44:09</td>\n",
              "      <td>Wed Nov 12 12:41:32 +0000 2014</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>532513524460052480</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>&lt;a href=\"http://www.facebook.com/twitter\" rel=...</td>\n",
              "      <td>Tutti a tavola, con il filetto di baccalÃ . ht...</td>\n",
              "      <td>2014-11-12 13:41:32</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2014-11-12 21:44:09</td>\n",
              "      <td>24858289.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2014-11-12 21:44:09</td>\n",
              "      <td>Tue Nov 11 22:23:43 +0000 2014</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>532297646669852672</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>&lt;a href=\"http://www.facebook.com/twitter\" rel=...</td>\n",
              "      <td>http://t.co/NAHQ4l2pUy</td>\n",
              "      <td>2014-11-11 23:23:43</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2014-11-12 21:44:09</td>\n",
              "      <td>24858289.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2014-11-12 21:44:09</td>\n",
              "      <td>Tue Nov 11 22:17:01 +0000 2014</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>532295960807100416</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>&lt;a href=\"http://www.facebook.com/twitter\" rel=...</td>\n",
              "      <td>Gold - Spandau Ballet http://t.co/o8ZJHt7Neu</td>\n",
              "      <td>2014-11-11 23:17:01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2014-11-12 21:44:09</td>\n",
              "      <td>24858289.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70b1e6fe-16de-454c-9511-17abcc2bd436')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70b1e6fe-16de-454c-9511-17abcc2bd436 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70b1e6fe-16de-454c-9511-17abcc2bd436');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "0_hQfFN8D53u"
      },
      "outputs": [],
      "source": [
        "df1 = df[['user_id','num_hashtags','num_urls','num_mentions','retweet_count','is_bot']] #create dataframe containing tweet information\n",
        "df2 = df[['user_id','text']] #create dataframe for tweets to calcukate semantic analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Uw6fJh4UwTjB"
      },
      "outputs": [],
      "source": [
        "sid_obj = SentimentIntensityAnalyzer() #variable for sentiment calculator\n",
        "def subject_calc(text): #function to calculate subjectivity of tweets\n",
        "    try:\n",
        "        return TextBlob(text).sentiment.subjectivity \n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def sentiment_calc(text): #function to calculate sentiment of tweets\n",
        "    try:\n",
        "        return  sid_obj.polarity_scores(text)\n",
        "    except:\n",
        "        return 0\n",
        "        \n",
        "def mean_embeddings(s):\n",
        "    \"\"\"Transfer a list of words into mean embedding\"\"\"\n",
        "    return np.mean([glove_vec.get_vector(x) for x in s if x in glove_vec], axis=0) #function to extract word embedding for words in tweetsd embedding for words in tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVpAjNVBTj2y"
      },
      "outputs": [],
      "source": [
        "df2['subjectivity_score'] = df2['text'].apply(subject_calc) #Apply function calculating subjectivity of an tweet to each tweet \n",
        "df2['sentiment_score'] = df2['text'].apply(sentiment_calc) #Apply function calculating sentiment scores of an tweet to each tweet\n",
        "df2 = pd.concat([df2.drop(['sentiment_score'], axis=1), df2['sentiment_score'].apply(pd.Series)], axis=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_0_LY6NTzQO",
        "outputId": "72aa986a-d537-4d45-aa39-fe9e18f64568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "glove_vec = gensim.downloader.load('glove-twitter-25') #upload glove embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MUoe1nodRrGj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8202a6da-b836-474f-834a-765b65c4aae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 6026.30it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 28455.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'I': 1, 'Pooh': 1, '-': 2, 'In': 1, 'silenzio': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import operator  #used to build vocabulary to check similarity between word embeddings and tweet tokens\n",
        "\n",
        "\n",
        "def check_coverage(vocab,embeddings_index):\n",
        "    a = {}\n",
        "    oov = {}\n",
        "    k = 0\n",
        "    i = 0\n",
        "    for word in tqdm(vocab):\n",
        "        try:\n",
        "            a[word] = embeddings_index[word]\n",
        "            k += vocab[word]\n",
        "        except:\n",
        "\n",
        "            oov[word] = vocab[word]\n",
        "            i += vocab[word]\n",
        "            pass\n",
        "\n",
        "    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
        "    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
        "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
        "\n",
        "    return sorted_x\n",
        "\n",
        "def build_vocab(sentences, verbose =  True):\n",
        "    \"\"\"\n",
        "    :param sentences: list of list of words\n",
        "    :return: dictionary of words and their count\n",
        "    \"\"\"\n",
        "    vocab = {}\n",
        "    for sentence in tqdm(sentences, disable = (not verbose)):\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                vocab[word] += 1\n",
        "            except KeyError:\n",
        "                vocab[word] = 1\n",
        "    return vocab\n",
        "df2['text']=df2['text'].fillna('').apply(str)\n",
        "sentences = df2['text'].progress_apply(lambda x: x.split()).values\n",
        "vocab = build_vocab(sentences)\n",
        "print({k: vocab[k] for k in list(vocab)[:5]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "F5uEDQ4VIj3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf59a26-a04b-443c-d737-444df82efd95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 10300.35it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 10496.26it/s]\n",
            "100%|██████████| 5/5 [00:00<00:00, 3685.68it/s]\n"
          ]
        }
      ],
      "source": [
        "def preprocessing (tweet):\n",
        "  #Remove RT\n",
        "  tweet2 = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "  #  Replace hyperlinks with URL\n",
        "  tweet2 = re.sub(r'https?:\\/\\/.*[\\r\\n]*', ' url ', tweet2)\n",
        "  #  Replace hashtags with 'hashtag' \n",
        "  tweet2 = re.sub(r'#', ' hashtag ', tweet2)\n",
        "  # Replace @User with user\n",
        "  tweet2 = re.sub(r'@[A-Za-z0-9]+', ' user ', tweet2)\n",
        "  #Remove \\n from text\n",
        "  tweet2 = re.sub(r'\\n', '', tweet2)\n",
        "  #Replace date values with date\n",
        "  tweet2 = re.sub(r'(\\d+/\\d+/\\d+)', 'date', tweet2)\n",
        "  #Remove the connectors for the emoji's\n",
        "  tweet2 = re.sub(r'_', ' ', tweet2)\n",
        "  tweet2 = re.sub(r'-', ' ', tweet2)\n",
        "  # Replace numeric terms in the tweet with 'number'.\n",
        "  tweet2 = re.sub(r'/^[+-]?((\\d+(\\.\\d*)?)|(\\.\\d+))$/', ' number ', tweet2)\n",
        "  return (tweet2)\n",
        "\n",
        "\n",
        "def _get_mispell(mispell_dict):\n",
        "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
        "    return mispell_dict, mispell_re\n",
        "\n",
        "\n",
        "mispell_dict = {\"i’m\":\"i am\",\n",
        "                \"isn’t\":\"is not\",\n",
        "                \"it’s\":\"it is\",\n",
        "                \"don’t\":\"do not\",\n",
        "                \"can’t\":\"can not\",\n",
        "                \"we're\":\"we are\",\n",
        "                \"that's\":\"that is\",\n",
        "                \"i've\":\"i have\",\n",
        "                \"you’re\":\"you are\",\n",
        "                \"he’s\":\"he is\",\n",
        "                \"couldn't\":\"could not\",\n",
        "                \"wouldn't\":\"would not\",\n",
        "                \"shouldn't\":\"should not\",\n",
        "                \"ain't\":\"are not\",\n",
        "                }\n",
        "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
        "\n",
        "def replace_typical_misspell(text):\n",
        "    def replace(match):\n",
        "        return mispellings[match.group(0)]\n",
        "\n",
        "    return mispellings_re.sub(replace, text)\n",
        "\n",
        "def clean_numbers(x):\n",
        "    #replace number from text with #\n",
        "    x = re.sub('[0-9]{5,}', '#####', x)\n",
        "    x = re.sub('[0-9]{4}', '####', x)\n",
        "    x = re.sub('[0-9]{3}', '###', x)\n",
        "    x = re.sub('[0-9]{2}', '##', x)\n",
        "    x = re.sub('[0-9]', '#', x)\n",
        "    return x\n",
        "\n",
        "def clean_text(x):\n",
        "   #remove punctuation from text\n",
        "    x = str(x)\n",
        "    for punct in \"/-'\":\n",
        "        x = x.replace(punct, ' ')\n",
        "    for punct in '&':\n",
        "        x = x.replace(punct, f' {punct} ')\n",
        "    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~' + '“”’':\n",
        "        x = x.replace(punct, '')\n",
        "    return x\n",
        "df2['text'] = df2['text'].fillna('').apply(str) \n",
        "df2['text'] = df2['text'].apply(lambda x: emoji.demojize(x, delimiters=(\" \", \" \")))#apply emoji transformer\n",
        "df2['text'] = df2['text'].progress_apply(lambda x: replace_typical_misspell(x))#apply preprocessing concatenated words into seperate words\n",
        "df2['text'] = df2['text'].apply(preprocessing)#apply preprocessing\n",
        "df2['text'] = df2['text'].apply(lambda x: clean_text(x))\n",
        "df2['text'] = df2['text'].progress_apply(lambda x: clean_numbers(x)) #apply preprocessing to transform numbers\n",
        "df2['text'] = df2['text'].apply(lambda x:x.lower())#lower text\n",
        "df2['text'] = df2['text'].progress_apply(lambda x: word_tokenize(x)) #tokenise text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jz5DbBcdR0uE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb40c041-fced-4d40-c490-63a42a2f8f94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 30393.51it/s]\n",
            "100%|██████████| 17/17 [00:00<00:00, 37468.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found embeddings for 94.12% of vocab\n",
            "Found embeddings for  95.83% of all text\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "vocab = build_vocab(df2['text']) \n",
        "oov = check_coverage(vocab,glove_vec) # compares all of tweets with words in word embedding "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_0SPDlgSR72f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac13095d-fea3-43f6-cc79-6d5b17e1ff52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('baccalã', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "oov[:20]#provides list of words that are in tweets and not in word embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "a6y3hCgW_nWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34b67151-55d0-4236-a16a-6132d19747a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 2069.83it/s]\n"
          ]
        }
      ],
      "source": [
        "df2[\"Text_Sim\"] = df2['text'].progress_apply(lambda x: mean_embeddings(x)) # extract 'embeddings' for each group\n",
        "h = []\n",
        "df2 = df2.dropna(subset=['Text_Sim']) #drop rows that have NAN values\n",
        "s = df2.groupby(\"user_id\")\n",
        "h = s['Text_Sim'].apply(np.stack).apply(cosine_similarity).apply(np.mean).reset_index()\n",
        "#  .apply(np.stack) # turns sequence of arrays into proper matrix\n",
        "#  .apply(cosine_similarity) # compute pairwise similarity matrix\n",
        "#  .apply(np.mean) # get the mean"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df1.groupby(\"user_id\").mean().reset_index() # calculate average of Tweet content information\n",
        "df2=df2.groupby(\"user_id\").mean().reset_index() # calculate average of semantic analysis of Tweet information"
      ],
      "metadata": {
        "id": "vxq6R0VzBhwk"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#concat users profile info, processed Tweet Content, and Tweet Semantic Analysis\n",
        "df1 = pd.merge(h,df1,on=[\"user_id\"])\n",
        "df1 = pd.merge(df2,df1,on=[\"user_id\"])\n",
        "df1 = df1.rename(columns={\"user_id\": \"id\"})#rename dataframe column \n",
        "df1['id'] = df1['id'].astype(\"float\").astype(\"Int64\")\n",
        "df1 = df1.drop(columns=['is_bot'])\n",
        "users = users.merge(df1,how='left', left_on=\"id\", right_on=\"id\")#merge so no information is lost"
      ],
      "metadata": {
        "id": "rU2z5TruXc6R"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users # should be concated dataframe of all features"
      ],
      "metadata": {
        "id": "3Yz8NZf4IqKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZKPJdQDM8br"
      },
      "outputs": [],
      "source": [
        "df = users\n",
        "df.to_csv('/content/drive/My Drive/preprocess.csv',encoding='utf-8',index=False) #create processed dataframe for machine learning model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "BotDetection2017Preprocess.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNeI2YFGCx5qJen/e+XHtrr",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}